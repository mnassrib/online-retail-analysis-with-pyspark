{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Retail Analysis with Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Assignment Statement\n",
    "\n",
    "You are given a dataset with several transactions spanning from 2010 to 2011, across multiple countries and several invoices and products.\n",
    "\n",
    "What we want you to do is to create a python program that is able to import this dataset inside a MongoDB. Then, you need to set up and use Apache Spark (https://docs.mongodb.com/spark-connector/current/) in order to manipulate the data.\n",
    "\n",
    "What we need is:\n",
    "\n",
    "• Group all transactions by invoice\n",
    "\n",
    "• Which product sold the most?\n",
    "\n",
    "• Which customer spent the most money?\n",
    "\n",
    "• Give as a chart showing the distribution of each product for each of the available countries (for this you can answer by providing a view or a new collection, you can provide the chart with a graphic outside the code).\n",
    "\n",
    "• What is the average unit price?\n",
    "\n",
    "• Give us a chart showing the distribution of prices.\n",
    "\n",
    "• Give us the ratio between price and quantity for each invoice.\n",
    "\n",
    "All these answers can be provided either by creating a view for each or an API route. Make sure that your code is documented, clean and tested (we expect at least unit tests with a coverage of over 80%).\n",
    "\n",
    "You can use docker and ready-made docker images.\n",
    "\n",
    "You need to push your code in a public repository (github, bitbucket etc). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the dataset inside a MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mongodbdata(file_path, sheet_name, host_path, db_name, collection_name):\n",
    "    \"\"\"\n",
    "    - mongodbdata function loads data from xlsx file  \n",
    "    - It creates and returns the data as a pandas dataframe\n",
    "    - It creates a database inside mongodb \n",
    "    - It injects the data as collection inside the database\n",
    "    \"\"\"\n",
    "    \n",
    "    # Checking if the file extension is '.xlsx'\n",
    "    if not file_path.endswith('.xlsx'):\n",
    "        raise TypeError('the file format or extension is not valid xlsx')\n",
    "    # Read an Excel file into a pandas DataFrame\n",
    "    df = pd.read_excel(io=file_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Connect to MongoDB\n",
    "    client = MongoClient(host_path)\n",
    "    # Create database db_name\n",
    "    db = client[db_name]\n",
    "    # drop collection collection_name if exists \n",
    "    db[collection_name].drop()\n",
    "    # Create collection collection_name\n",
    "    collection = db[collection_name]\n",
    "    # Insert collection\n",
    "    collection.insert_many(df.to_dict(\"records\"))\n",
    "    # Checking if The collection was successfully created\n",
    "    try:\n",
    "        client[db_name].validate_collection(collection_name)  # Try to validate a collection\n",
    "        print(f\"The collection {collection_name} is successfully created\")\n",
    "    except pymongo.errors.OperationFailure:  # If the collection doesn't exist\n",
    "        print(f\"The collection {collection_name} is not yet created\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The collection retail is successfully created\n"
     ]
    }
   ],
   "source": [
    "# Importing useful libraries\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Path where the Excel file is stored\\File\n",
    "file_path = \"data/Online Retail.xlsx\"\n",
    "# Name of the sheet\n",
    "sheet_name = \"Online Retail\"\n",
    "# hostname or IP address\n",
    "host_path = \"mongodb://localhost:27017/\"\n",
    "# Mongo database name \n",
    "db_name = \"online_retail\" \n",
    "# Name of the collection\n",
    "collection_name = \"retail\"\n",
    "\n",
    "# Load the dataframe for pandas and creating a database \n",
    "df = mongodbdata(file_path, sheet_name, host_path, db_name, collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let show some rows from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
       "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
       "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and using Apache Spark to manipulate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Set up PySpark data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiation and create a SparkSession. No need to create SparkContext\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# The entry point into all functionality in Spark is the SparkSession class. \n",
    "# Create a SparkSession using SparkSession.builder:\n",
    "# Specify the spark.mongodb.input.uri and spark.mongodb.output.uri configuration options to connect to mongodb databases\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Online Retail Analysis with Pyspark\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1/online_retail.retail\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/online_retail.retail\") \\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.11:2.3.1') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "def spark_shape(self):\n",
    "    \"\"\"\n",
    "    spark_shape function returns the shape of a distributed collection of data grouped into named columns.\n",
    "    \"\"\"\n",
    "    return (self.count(), len(self.columns))\n",
    "\n",
    "# Adding spark_shape function to the native functions of spark\n",
    "pyspark.sql.dataframe.DataFrame.shape = spark_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------------+-------------------+---------+--------+---------+---------+--------------------+\n",
      "|       Country|CustomerID|         Description|        InvoiceDate|InvoiceNo|Quantity|StockCode|UnitPrice|                 _id|\n",
      "+--------------+----------+--------------------+-------------------+---------+--------+---------+---------+--------------------+\n",
      "|United Kingdom|   17850.0|WHITE HANGING HEA...|2010-12-01 09:26:00|   536365|       6|   85123A|     2.55|[61b142e476788d54...|\n",
      "|United Kingdom|   17850.0| WHITE METAL LANTERN|2010-12-01 09:26:00|   536365|       6|    71053|     3.39|[61b142e476788d54...|\n",
      "|United Kingdom|   17850.0|CREAM CUPID HEART...|2010-12-01 09:26:00|   536365|       8|   84406B|     2.75|[61b142e476788d54...|\n",
      "|United Kingdom|   17850.0|KNITTED UNION FLA...|2010-12-01 09:26:00|   536365|       6|   84029G|     3.39|[61b142e476788d54...|\n",
      "|United Kingdom|   17850.0|RED WOOLLY HOTTIE...|2010-12-01 09:26:00|   536365|       6|   84029E|     3.39|[61b142e476788d54...|\n",
      "+--------------+----------+--------------------+-------------------+---------+--------+---------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the distributed data from mongodb\n",
    "dfs = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "\n",
    "# Showing the first 5 lines\n",
    "dfs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distributed data shape: (541909, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"The distributed data shape:\", dfs.shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>summary</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>stddev</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>541909</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerID</th>\n",
       "      <td>541909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12346.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <td>541909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4 PURPLE FLOCK DINNER CANDLES</td>\n",
       "      <td>wrongly sold sets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InvoiceNo</th>\n",
       "      <td>541909</td>\n",
       "      <td>559965.752026781</td>\n",
       "      <td>13428.417280795753</td>\n",
       "      <td>536365</td>\n",
       "      <td>C581569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantity</th>\n",
       "      <td>541909</td>\n",
       "      <td>9.55224954743324</td>\n",
       "      <td>218.0811578502347</td>\n",
       "      <td>-80995</td>\n",
       "      <td>80995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StockCode</th>\n",
       "      <td>541909</td>\n",
       "      <td>27623.240210938104</td>\n",
       "      <td>16799.73762842769</td>\n",
       "      <td>10002</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UnitPrice</th>\n",
       "      <td>541909</td>\n",
       "      <td>4.611113626080558</td>\n",
       "      <td>96.75985306117857</td>\n",
       "      <td>-11062.06</td>\n",
       "      <td>38970.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "summary       count                mean              stddev  \\\n",
       "Country      541909                None                None   \n",
       "CustomerID   541909                 NaN                 NaN   \n",
       "Description  541909                 NaN                 NaN   \n",
       "InvoiceNo    541909    559965.752026781  13428.417280795753   \n",
       "Quantity     541909    9.55224954743324   218.0811578502347   \n",
       "StockCode    541909  27623.240210938104   16799.73762842769   \n",
       "UnitPrice    541909   4.611113626080558   96.75985306117857   \n",
       "\n",
       "summary                                 min                max  \n",
       "Country                           Australia        Unspecified  \n",
       "CustomerID                          12346.0                NaN  \n",
       "Description   4 PURPLE FLOCK DINNER CANDLES  wrongly sold sets  \n",
       "InvoiceNo                            536365            C581569  \n",
       "Quantity                             -80995              80995  \n",
       "StockCode                             10002                  m  \n",
       "UnitPrice                         -11062.06            38970.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calculate some useful statistics\n",
    "summary = dfs.describe().toPandas()\n",
    "summary = summary.T\n",
    "summary.columns = summary.iloc[0]\n",
    "summary = summary.drop(summary.index[0])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table column count suggests that there are missing values in Description and CustomerID columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------+---------+--------+---------+---------+\n",
      "|Country|CustomerID|Description|InvoiceNo|Quantity|StockCode|UnitPrice|\n",
      "+-------+----------+-----------+---------+--------+---------+---------+\n",
      "|      0|    135080|       1454|        0|       0|        0|        0|\n",
      "+-------+----------+-----------+---------+--------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Let's display the number of those missing values \n",
    "dfs.select([F.count(F.when(F.isnan(c), c)).alias(c) for c in dfs.columns if c not in [\"InvoiceDate\", \"_id\"]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------+---------+--------+---------+---------+\n",
      "|Country|CustomerID|Description|InvoiceNo|Quantity|StockCode|UnitPrice|\n",
      "+-------+----------+-----------+---------+--------+---------+---------+\n",
      "|      0|         0|          0|        0|       0|        0|        0|\n",
      "+-------+----------+-----------+---------+--------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removing those missing values and checking if there are still missing values\n",
    "dfs = dfs.dropna(subset=[\"Description\", \"CustomerID\"])\n",
    "dfs.select([F.count(F.when(F.isnan(c), c)).alias(c) for c in dfs.columns if c not in [\"InvoiceDate\", \"_id\"]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the schema in the tree format of the distributed data collection\n",
    "dfs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The customerID column type is double. It is recommended to change its type to Integer because it is an ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert double to Integer Type\n",
    "dfs = dfs.withColumn(\"CustomerID\", dfs.CustomerID.cast('int'))\n",
    "dfs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------------+-------------------+---------+--------+---------+---------+--------------------+\n",
      "|       Country|CustomerID|         Description|        InvoiceDate|InvoiceNo|Quantity|StockCode|UnitPrice|                 _id|\n",
      "+--------------+----------+--------------------+-------------------+---------+--------+---------+---------+--------------------+\n",
      "|United Kingdom|     17850|WHITE HANGING HEA...|2010-12-01 09:26:00|   536365|       6|   85123A|     2.55|[61b142e476788d54...|\n",
      "|United Kingdom|     17850| WHITE METAL LANTERN|2010-12-01 09:26:00|   536365|       6|    71053|     3.39|[61b142e476788d54...|\n",
      "|United Kingdom|     17850|CREAM CUPID HEART...|2010-12-01 09:26:00|   536365|       8|   84406B|     2.75|[61b142e476788d54...|\n",
      "|United Kingdom|     17850|KNITTED UNION FLA...|2010-12-01 09:26:00|   536365|       6|   84029G|     3.39|[61b142e476788d54...|\n",
      "+--------------+----------+--------------------+-------------------+---------+--------+---------+---------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The InvoiceNo transactions seem not all starting with letter \"5\". Removing all transactions that start with a letter different from \"5\" in the InvoiceNo column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|InvoiceNo_first_char| count|\n",
      "+--------------------+------+\n",
      "|                   5|397924|\n",
      "|                   C|  8905|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting the distinct beginning letters of the InvoiceNo column\n",
    "dfs.withColumn(\"InvoiceNo_first_char\", dfs.InvoiceNo.substr(1,1)).groupBy([\"InvoiceNo_first_char\"]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397924, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing all rows having the first letter different from 5 into the InvoiceNo column\n",
    "dfs = dfs.filter(dfs.InvoiceNo.substr(1,1) == \"5\")\n",
    "dfs.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|InvoiceNo_first_char| count|\n",
      "+--------------------+------+\n",
      "|                   5|397924|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking by counting the distinct beginning letters of the InvoiceNo column\n",
    "dfs.withColumn(\"InvoiceNo_first_char\", dfs.InvoiceNo.substr(1,1)).groupBy([\"InvoiceNo_first_char\"]).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the Country column contains an incorrect name for Ireland. We will have to correct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------+-----------+---------+--------+---------+---------+---+\n",
      "|Country|CustomerID|Description|InvoiceDate|InvoiceNo|Quantity|StockCode|UnitPrice|_id|\n",
      "+-------+----------+-----------+-----------+---------+--------+---------+---------+---+\n",
      "+-------+----------+-----------+-----------+---------+--------+---------+---------+---+\n",
      "\n",
      "+--------------+----------+--------------------+-------------------+---------+--------+---------+---------+--------------------+\n",
      "|       Country|CustomerID|         Description|        InvoiceDate|InvoiceNo|Quantity|StockCode|UnitPrice|                 _id|\n",
      "+--------------+----------+--------------------+-------------------+---------+--------+---------+---------+--------------------+\n",
      "|United Kingdom|     17850|WHITE HANGING HEA...|2010-12-01 09:26:00|   536365|       6|   85123A|     2.55|[61b142e476788d54...|\n",
      "|United Kingdom|     17850| WHITE METAL LANTERN|2010-12-01 09:26:00|   536365|       6|    71053|     3.39|[61b142e476788d54...|\n",
      "|United Kingdom|     17850|CREAM CUPID HEART...|2010-12-01 09:26:00|   536365|       8|   84406B|     2.75|[61b142e476788d54...|\n",
      "|United Kingdom|     17850|KNITTED UNION FLA...|2010-12-01 09:26:00|   536365|       6|   84029G|     3.39|[61b142e476788d54...|\n",
      "|United Kingdom|     17850|RED WOOLLY HOTTIE...|2010-12-01 09:26:00|   536365|       6|   84029E|     3.39|[61b142e476788d54...|\n",
      "+--------------+----------+--------------------+-------------------+---------+--------+---------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if exists Ireland country name\n",
    "dfs.filter(dfs.Country == \"Ireland\").show(5)\n",
    "# Replace all EIRE country name by Ireland country name\n",
    "dfs = dfs.replace(['EIRE'],['Ireland'])\n",
    "dfs.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark supports SQL - Structured Query Language - which traditionally has an important role in managing relational databases. The use of SQL queries offers a lot of flexibility for data analyses. Let us experiment with some very useful SQL queries, such as select and filter. We first need to register the DataFrame as a temporary table in the SQLContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the distributed dataframe as a temporary table in the SQLContext\n",
    "dfs.registerTempTable(\"dfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|         Description|Quantity|\n",
      "+--------------------+--------+\n",
      "|WHITE HANGING HEA...|       6|\n",
      "| WHITE METAL LANTERN|       6|\n",
      "|CREAM CUPID HEART...|       8|\n",
      "|KNITTED UNION FLA...|       6|\n",
      "|RED WOOLLY HOTTIE...|       6|\n",
      "|SET 7 BABUSHKA NE...|       2|\n",
      "|GLASS STAR FROSTE...|       6|\n",
      "+--------------------+--------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Description, Quantity from dfs\").show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Group all transactions by invoice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count the number of transactions for each invoice, I propose two equivalent solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|InvoiceNo|sum(Quantity)|\n",
      "+---------+-------------+\n",
      "|   536938|          464|\n",
      "|   537691|          163|\n",
      "|   538184|          314|\n",
      "|   538517|          161|\n",
      "|   538879|          402|\n",
      "|   539275|          156|\n",
      "|   539630|          244|\n",
      "+---------+-------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sol1 = dfs.groupBy([\"InvoiceNo\"]).agg(F.sum(\"Quantity\"))\n",
    "sol1.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|InvoiceNo|sum(Quantity)|\n",
      "+---------+-------------+\n",
      "|   536938|          464|\n",
      "|   537691|          163|\n",
      "|   538184|          314|\n",
      "|   538517|          161|\n",
      "|   538879|          402|\n",
      "|   539275|          156|\n",
      "|   539630|          244|\n",
      "+---------+-------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sol2 = dfs[\"InvoiceNo\", \"Quantity\"].groupBy('InvoiceNo').sum()\n",
    "sol2.show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Which product sold the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see which product is selling the most, it is necessary to determine how many times each existing product in the Description column is called. To do this, select only the \"Description\" and \"Quantity\" columns and grouping by \"Description\" while aggregating by sum. Finally, do descending sort of the obtained dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|         Description|sum(Quantity)|\n",
      "+--------------------+-------------+\n",
      "|PAPER CRAFT , LIT...|        80995|\n",
      "|MEDIUM CERAMIC TO...|        77916|\n",
      "|WORLD WAR 2 GLIDE...|        54415|\n",
      "|JUMBO BAG RED RET...|        46181|\n",
      "|WHITE HANGING HEA...|        36725|\n",
      "|ASSORTED COLOUR B...|        35362|\n",
      "|PACK OF 72 RETROS...|        33693|\n",
      "+--------------------+-------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solded_products = dfs[\"Description\", \"Quantity\"].groupBy('Description').sum().orderBy(F.col(\"sum(Quantity)\").desc())\n",
    "\n",
    "solded_products.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best-selling product is PAPER CRAFT , LITTLE BIRDIE with 80995 quantities.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best-selling product is {solded_products.first()[0]} with {solded_products.first()[1]} quantities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Which customer spent the most money?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same principle as the previous question, here I'll add new column \"Spent\" that represent the total expenses for each row by multiply the Quantity with the UnitPrice. I keep only two columns: \"CustomerID\" and \"Spent\" and grouping by CustomerID while aggregating by sum. Finally, do descending sort of the obtained dataframe. It is recommended to round the obtained values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerID|             Spent|\n",
      "+----------+------------------+\n",
      "|     17850|15.299999999999999|\n",
      "|     17850|             20.34|\n",
      "|     17850|              22.0|\n",
      "|     17850|             20.34|\n",
      "+----------+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_spent = dfs.withColumn(\"Spent\", F.col(\"Quantity\") * F.col(\"UnitPrice\"))[\"CustomerID\", \"Spent\"]\n",
    "customers_spent.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|CustomerID|sum(Spent)|\n",
      "+----------+----------+\n",
      "|     14646| 280206.02|\n",
      "|     18102|  259657.3|\n",
      "|     17450| 194550.79|\n",
      "|     16446|  168472.5|\n",
      "|     14911| 143825.06|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_customers_spent = customers_spent.groupBy([\"CustomerID\"]).agg(F.sum(\"Spent\")).orderBy(F.col(\"sum(Spent)\").desc())\n",
    "most_customers_spent = most_customers_spent.withColumn(\"sum(Spent)\", F.round(most_customers_spent[\"sum(Spent)\"], 2))   \n",
    "most_customers_spent.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Customer spending the most money is CutomerID number {most_customers_spent.first()[0]} with money spent of {most_customers_spent.first()[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Chart showing the distribution of each product for each of the available countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give the distribution of each product for each of the available countries, it is required to calculate how much the expenses in each row by multiplying the Quantity with the UnitPrice. A new column called \"Exp\" will be added. Selecting only the \"Country\" and \"Exp\" columns and grouping by \"Country\" while aggregating over the sum produces a new dataframe that gives the total expenses for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expc = dfs.withColumn(\"Exp\", F.col(\"Quantity\") * F.col(\"UnitPrice\"))[\"Country\", \"Exp\"].groupBy('Country').sum()\n",
    "expc = expc.withColumn(\"sum(Exp)\", F.round(expc[\"sum(Exp)\"], 2))  \n",
    "expc.orderBy(F.col(\"sum(Exp)\").desc()).show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will convert the above distributed dataframe to a pandas dataframe by adding a new column \"iso_alpha\" mentioning the ISO Alpha-3 code for each country. Some corrections will be made to some country names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_exp = expc.toPandas()\n",
    "country_exp.loc[country_exp[\"Country\"] == \"RSA\", \"Country\"] = \"South Africa\"\n",
    "country_exp.loc[country_exp[\"Country\"] == \"USA\", \"Country\"] = \"United States\"\n",
    "country_exp.loc[country_exp[\"Country\"] == \"Channel Islands\", \"Country\"] = \"United Kingdom\"\n",
    "country_exp = country_exp.groupby(['Country']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "countries_codes = {}\n",
    "for country in pycountry.countries:\n",
    "    countries_codes[country.name] = country.alpha_3\n",
    "\n",
    "country_exp['iso_alpha'] = [countries_codes.get(country, 'Unknown code') for country in country_exp.index]\n",
    "country_exp.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use plotly.express as well as plotly.graph_objectsuse to build two equivalent charts that will disply the distribution of each product for each of the available countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import iplot\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth(country_exp, locations=\"iso_alpha\",\n",
    "                    color=\"sum(Exp)\", \n",
    "                    hover_name=country_exp.index, # column to add to hover information\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Choropleth(\n",
    "    locations = country_exp['iso_alpha'],\n",
    "    z = country_exp['sum(Exp)'],\n",
    "    text = country_exp.index,\n",
    "    colorscale = 'Blues',\n",
    "    autocolorscale=False,\n",
    "    reversescale=True,\n",
    "    marker_line_color='darkgray',\n",
    "    marker_line_width=0.5,\n",
    "    colorbar_tickprefix = '',\n",
    "    colorbar_title = 'Exp',\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Country Exp',\n",
    "    geo=dict(\n",
    "        showframe=False,\n",
    "        showcoastlines=False,\n",
    "        projection_type='equirectangular'\n",
    "    ),\n",
    ")\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Average unit price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the previous question, to compute the average unit price, it is required to calculate how much the expenses in each row by multiplying the Quantity with the UnitPrice. A new column called \"Exp\" will be added. Selecting only the \"Quantity\" and \"Exp\" columns while aggregating over the sum gives a new dataframe with the total expenses and the total quantity (sum(Exp) and sum(Quantity) repectively). The average is the division of sum(Exp) by sum(Quantity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expq = dfs.withColumn(\"Exp\", F.col(\"Quantity\") * F.col(\"UnitPrice\"))[\"Quantity\", \"Exp\"]\n",
    "expq.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = expq.groupBy().sum().withColumn(\"Average UnitPrice\", F.col(\"sum(Exp)\")/F.col(\"sum(Quantity)\"))\n",
    "average = average.withColumn(\"sum(Exp)\", F.round(average[\"sum(Exp)\"], 2)) \n",
    "average = average.withColumn(\"Average UnitPrice\", F.round(average[\"Average UnitPrice\"], 2))  \n",
    "average.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The average unit price is {average.collect()[0]['Average UnitPrice']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Chart showing the distribution of prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the distribution of prices, it is necessary to extract the month and year from the InvoiceDate column. Then, calculate total expenses according to each month as well as to each year. The resulting distributed dataframe will be converted into a pandas dataframe in order to use it to plot the chart using the Seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dist = dfs.withColumn(\"Exp\", F.col(\"Quantity\") * F.col(\"UnitPrice\"))\n",
    "price_dist = price_dist.withColumn('Month', F.month(F.col('InvoiceDate')))\n",
    "price_dist = price_dist.withColumn('Year', F.year(F.col('InvoiceDate')))['Year', \"Month\", \"Exp\"]\n",
    "\n",
    "price_dist = price_dist.groupBy([\"Month\", \"Year\"]).agg(F.sum(\"Exp\")).orderBy(F.col(\"Month\"))\n",
    "price_dist = price_dist.withColumn(\"sum(Exp)\", F.round(price_dist[\"sum(Exp)\"], 2))\n",
    "price_dist.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pdf = price_dist.toPandas()\n",
    "\n",
    "plt.figure(figsize=[15,7])\n",
    "g = sns.barplot(x='Month', y='sum(Exp)', hue='Year', data=pdf)\n",
    "g.set_title('Distribution of prices per month');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Ratio between price and quantity for each invoice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the Ratio between price and quantity for each invoice, it is required to calculate how much the expenses in each row by multiplying the Quantity with the UnitPrice into new column called \"Exp\". A grouping by the InvoiceNo column while aggregating over the sum gives a new dataframe with the total expenses and the total quantity (sum(Exp) and sum(Quantity) repectively). By keeping only the 'InvoiceNo', 'sum(Quantity)' and \"sum(Exp)\" columns, the ratio for each InvoiceNo is obtained by dividing for each row the \"sum(Exp)\" value by the \"sum(Quantity)\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = dfs.withColumn(\"Exp\", F.col(\"Quantity\") * F.col(\"UnitPrice\"))['InvoiceNo', 'Quantity', \"Exp\"]\n",
    "ratio = ratio.groupBy([\"InvoiceNo\"]).sum()['InvoiceNo', 'sum(Quantity)', \"sum(Exp)\"]\n",
    "ratio = ratio.withColumn(\"Ratio\", F.col(\"sum(Exp)\")/F.col(\"sum(Quantity)\"))['InvoiceNo', \"Ratio\"]\n",
    "ratio = ratio.withColumn(\"Ratio\", F.round(ratio[\"Ratio\"], 2))\n",
    "ratio.show(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
